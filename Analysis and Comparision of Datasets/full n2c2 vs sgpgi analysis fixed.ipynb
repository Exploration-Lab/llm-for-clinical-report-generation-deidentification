{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e579f-da15-442e-a3cc-c5e81fb1fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8110af-9a3f-47ea-8447-9aa99d8b6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import lxml.etree as etree\n",
    "import re\n",
    "\n",
    "def escape_ampersands(content):\n",
    "    return re.sub(r'&(?!(amp;|lt;|gt;|apos;|quot;|#\\d+;))', '&amp;', content)\n",
    "\n",
    "def parse_xml(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read().strip()\n",
    "            content = escape_ampersands(content)\n",
    "        \n",
    "        parser = etree.XMLParser(recover=True)  \n",
    "        tree = etree.fromstring(content.encode('utf-8'), parser=parser)\n",
    "        if parser.error_log:\n",
    "            print(f\"Errors during parsing {file_path}:\")\n",
    "            for error in parser.error_log:\n",
    "                print(error.message, \"at line\", error.line)\n",
    "        \n",
    "        texts = tree.xpath('//TEXT//text()')\n",
    "        return ' '.join(texts)\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(f\"XMLSyntaxError while parsing file {file_path}: {str(e)}\")\n",
    "        print(f\"Content begins with: {content[:100]}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"General error with file {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_all_xml(root_directory):\n",
    "    all_texts = []\n",
    "    for root, dirs, files in os.walk(root_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.xml'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                text = parse_xml(file_path)\n",
    "                if text:\n",
    "                    all_texts.append(text)\n",
    "    return all_texts\n",
    "\n",
    "root_directory_1 = '/home/lokesh/ds_comparison/2006n2c2'\n",
    "collected_texts = process_all_xml(root_directory_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529e7de-b87c-4966-b3f2-4b77dab92baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58b565-5d8e-431f-80d9-05e87e056b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_texts_n2c2 = [clean_text(text) for text in collected_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac84318-b1c2-468d-a7bf-5de32600a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2c2_string = ' '.join(cleaned_texts_n2c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c1ec3-4e48-4f0d-a9fb-3a2c17b96de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2c2_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68edf754-56c4-445c-b81c-e9d411cb8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffce0d40-97ae-4a82-8620-c4dea53b883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b357296-60a5-4d53-8375-496a54950dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain = pd.read_excel('/home/lokesh/ds_comparison/n2c2_synthetic/1596_summary_gemini_final.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b5bb6-f8e5-4a8e-acc0-b29aa4e007db",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2c2_synthetic_list = dfTrain['Annotated_Summaries'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4702815f-739d-4755-8105-7b4f1daad192",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2c2_synthetic_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574bdc2-c999-4c95-be6c-274dbe11661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_strings = [s.replace('\\\\n', ' ') for s in n2c2_synthetic_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10bdae-4151-4c0f-8580-17770063cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251eb1f-ed32-430a-8201-92a97842aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_n2c2_string = ' '.join(cleaned_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be21f5b-dce7-413a-af3f-3f89db899a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_discharge_summary_n2c2 = n2c2_string + \"\\n\" + synthetic_n2c2_string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b02e9d0-68ef-47a6-aef9-0b239fc12f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_discharge_summary_n2c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e120f5-0587-4302-84bb-7c096076b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521e272-0c6a-4a72-ac0e-a21f267b58c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory_2 = '/lockbox/sgpgi_ds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf932c-e067-4224-aff4-508b06004b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_parse_jsonl(root_directory):\n",
    "    parsed_json_data = [] \n",
    "    for subdir, _, files in os.walk(root_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.jsonl'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        for line in f:\n",
    "                            try:\n",
    "                                json_data = json.loads(line)\n",
    "                                parsed_json_data.append(json_data)\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                print(f\"Error parsing JSON in file '{file_path}': {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file '{file_path}': {e}\")\n",
    "    return parsed_json_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e18f3b-a9f1-437c-9fba-149c23518715",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = extract_and_parse_jsonl(root_directory_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e2c37-309c-4cd1-873e-28075800b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e4aa3-5ee4-4961-ab15-84fca7368520",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_texts = [entry['text'] for entry in texts if 'text' in entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92775c48-c547-40cf-ab9a-460cc89d6f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_texts_sgpgi = [clean_text(text) for text in extracted_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d5818-d077-4d71-a7de-43934b8041b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgpgi_string = ' '.join(cleaned_texts_sgpgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f0810-57e5-4731-aba1-fe0180763781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def read_and_normalize_text_files(root_directory):\n",
    "    file_texts = []\n",
    "    for subdir, _, files in os.walk(root_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        text = f.read().replace('\\n', ' ')\n",
    "                        file_texts.append(text)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file '{file_path}': {e}\")\n",
    "    return file_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af1faa3-88c0-4b19-8b8a-aedf25b6abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_datapath_llama3 = '/lockbox/llama3_20240509/llama3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353bd8ad-7282-4960-bfd3-850f2d7081b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_text_llama3 = read_and_normalize_text_files(candidate_datapath_llama3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e08856e-6e2d-40d3-ba06-55ad59208a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_text_llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62af56e-0d71-4052-b46c-c01aaa89c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_syn_sgpgi = ' '.join(syn_text_llama3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1fc9b2-f287-4b3f-9d29-33a8fe91cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_discharge_summary_sgpgi = string_syn_sgpgi  + \"\\n\" + sgpgi_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c829f-9c39-4a39-9ece-e438264ea89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_discharge_summary_sgpgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ded01-af5b-4fb4-8ecf-f52a641a0ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0799bd45-0e53-4e37-a1a0-b37d405aeb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, bigrams, trigrams, FreqDist\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b337bc2-70fd-4d66-a13a-585fe6ae2420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f06bec-001e-4a72-be30-3125aa162eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_n2c2 = preprocess(combined_discharge_summary_n2c2)\n",
    "tokens_sgpgi = preprocess(combined_discharge_summary_sgpgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe6d31-0f7a-4ec3-bb67-5b04133db86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6531d7ba-299a-47e7-8226-7716f1c1117c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455bc358-270a-44f2-ba2a-9872cb0fa123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a447a1d-e848-43db-87a0-fed534abf6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4149b5-ad53-4322-8fee-b5bea1e723eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6972ac5-ce3f-4aa8-8874-c4b1389f7826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ea27f8-37eb-4533-b9c9-62ade8dca581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f365f-b092-40f9-b388-dc3fa1412652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26fd269-b282-46fb-8782-f057e7135971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(set1, set2):\n",
    "    \"\"\"Calculate the Jaccard distance between two sets.\"\"\"\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return 1 - len(intersection) / len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be8f190-1565-4fe0-a4a7-14da6586f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_n2c2 = set(tokens_n2c2)\n",
    "set_sgpgi = set(tokens_sgpgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9ce23-4167-4599-83aa-4f461bdce6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = jaccard_distance(set_n2c2, set_sgpgi)\n",
    "print(f\"Jaccard Distance: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170800ec-864f-4a7e-a6cc-27452132b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/lokesh/ds_comparison/bert_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d175ad6-504b-48d0-9064-a930b3102d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9a4ed-5a97-454d-9b54-9831ecb7a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P, R, F1 = score([n2c2_string], [sgpgi_string], lang='en', model_type=\"dmis-lab/biobert-v1.1\")\n",
    "print(\"Precision:\", P)\n",
    "print(\"Recall:\", R)\n",
    "print(\"F1 Score:\", F1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
